{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to decide how to deal with longitudinality. For now, we will ignore longitudinal data and treat each row as a unique patient. This means we need to take out any 'baseline' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ADNIMERGE.csv')\n",
    "all_cols = list(df)\n",
    "df.dtypes\n",
    "\n",
    "# baseline data is indicated by '_bl' OR described as a baseline measurement in ADNIMERGE_DICT\n",
    "important_cols = [i for i in all_cols[8:-3] if i[-2:] != 'bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_cols = ['RID'] + important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df[important_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AGE` is probably an important predictor for a diagnosis. However, ADNIMERGE_DICT says that `AGE` is the age of the patient at baseline. Because we are treating each row as a separate patient, we should use `Month_bl` (months from baseline) to calculate a 'new age' for each row. That is, a 65 year old who gets a second exam 12 months later will be treated as a different, 66 year old person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agasthyapradhan-shenoy/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['EXACT_AGE'] = df.AGE + (df.Month_bl/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agasthyapradhan-shenoy/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/agasthyapradhan-shenoy/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# now we need to one-hot encode the categorical predictors\n",
    "# BUT since we will eventually do a classification with DX,\n",
    "# we'll first convert those values and then one-hot encode\n",
    "# things like marriage, etc\n",
    "\n",
    "DX_class = []\n",
    "for i in data.DX.values:\n",
    "    if i == 'CN':\n",
    "        DX_class.append(0)\n",
    "    elif i == 'MCI':\n",
    "        DX_class.append(1)\n",
    "    elif i == 'Dementia':\n",
    "        DX_class.append(2)\n",
    "    else:\n",
    "        DX_class.append(i) # for NaNs. will deal with missingness next.\n",
    "\n",
    "# now drop the original DX column\n",
    "data.drop('DX',axis=1,inplace=True)\n",
    "\n",
    "# and replace with the new DX_class column\n",
    "data['DX_class'] = DX_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get columns with categorical data\n",
    "# by finding columns that have strings as entries\n",
    "cat_cols = [i for i in data.columns if isinstance(data[i][0], str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing to drop first because that was the \n",
    "# suggested best practice in HW3\n",
    "data = pd.get_dummies(data, columns = cat_cols, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13017, 55)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to deal with missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what percent of each column is missing?\n",
    "def percent_in_each_col(df):\n",
    "    percent_missing = [df[i].isnull().mean()*100 for i in list(df)]\n",
    "    percent_missing = np.asarray(percent_missing)\n",
    "    in_each = pd.DataFrame(percent_missing,df.columns,columns=[\"Percent\"])\n",
    "    print(in_each[in_each.Percent > 0])\n",
    "    print(\"Average percent missing for all columns: \", in_each[in_each.Percent > 0].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Percent\n",
      "APOE4                   0.453253\n",
      "FDG                    74.241377\n",
      "PIB                    98.286856\n",
      "AV45                   83.398633\n",
      "CDRSB                  30.736729\n",
      "ADAS11                 31.174618\n",
      "ADAS13                 31.835292\n",
      "MMSE                   29.522932\n",
      "RAVLT_immediate        30.383345\n",
      "RAVLT_learning         30.383345\n",
      "RAVLT_forgetting       30.583084\n",
      "RAVLT_perc_forgetting  31.120842\n",
      "FAQ                    29.000538\n",
      "MOCA                   60.052239\n",
      "EcogPtMem              59.360836\n",
      "EcogPtLang             59.483752\n",
      "EcogPtVisspat          59.798725\n",
      "EcogPtPlan             59.560575\n",
      "EcogPtOrgan            60.382577\n",
      "EcogPtDivatt           59.798725\n",
      "EcogPtTotal            59.453023\n",
      "EcogSPMem              59.099639\n",
      "EcogSPLang             59.061228\n",
      "EcogSPVisspat          59.829454\n",
      "EcogSPPlan             59.545210\n",
      "EcogSPOrgan            60.866559\n",
      "EcogSPDivatt           60.121380\n",
      "EcogSPTotal            59.099639\n",
      "Ventricles             42.790197\n",
      "Hippocampus            47.729892\n",
      "WholeBrain             40.915726\n",
      "Entorhinal             50.295767\n",
      "Fusiform               50.295767\n",
      "MidTemp                50.295767\n",
      "ICV                    38.887609\n",
      "DX_class               31.251440\n",
      "Average percent missing for all columns:  Percent    49.419349\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percent_in_each_col(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features have more than 50% of the data missing. This is because some tests were not used during certain protocols (ADNI1 vs ADNIGO, for example). Not sure exactly how to deal with that. Right now, we're just going to impute values for all the missing data, and see where that gets us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Percent]\n",
      "Index: []\n",
      "Average percent missing for all columns:  Percent   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# In lecture, Kevin mentioned that imputing using the median\n",
    "# will often give you the best results\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(strategy=\"median\")\n",
    "imputed = imp.fit_transform(data)\n",
    "full_data = pd.DataFrame(imputed,columns = data.columns)\n",
    "\n",
    "percent_in_each_col(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>FDG</th>\n",
       "      <th>PIB</th>\n",
       "      <th>AV45</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>...</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>PTMARRY_Married</th>\n",
       "      <th>PTMARRY_Never married</th>\n",
       "      <th>PTMARRY_Unknown</th>\n",
       "      <th>PTMARRY_Widowed</th>\n",
       "      <th>FLDSTRENG_3 Tesla MRI</th>\n",
       "      <th>FSVERSION_Cross-Sectional FreeSurfer (FreeSurfer Version 4.3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.36926</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.11467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>18.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09079</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.11467</td>\n",
       "      <td>4.5</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.06360</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.11467</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10384</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.11467</td>\n",
       "      <td>3.5</td>\n",
       "      <td>24.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03871</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.11467</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.67</td>\n",
       "      <td>37.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID   AGE  PTEDUCAT  APOE4      FDG   PIB     AV45  CDRSB  ADAS11  ADAS13  \\\n",
       "0  2.0  74.3      16.0    0.0  1.36926  1.85  1.11467    0.0   10.67   18.67   \n",
       "1  3.0  81.3      18.0    1.0  1.09079  1.85  1.11467    4.5   22.00   31.00   \n",
       "2  3.0  81.3      18.0    1.0  1.06360  1.85  1.11467    6.0   19.00   30.00   \n",
       "3  3.0  81.3      18.0    1.0  1.10384  1.85  1.11467    3.5   24.00   35.00   \n",
       "4  3.0  81.3      18.0    1.0  1.03871  1.85  1.11467    8.0   25.67   37.67   \n",
       "\n",
       "                               ...                                \\\n",
       "0                              ...                                 \n",
       "1                              ...                                 \n",
       "2                              ...                                 \n",
       "3                              ...                                 \n",
       "4                              ...                                 \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one  PTRACCAT_Unknown  \\\n",
       "0                         0.0                     0.0               0.0   \n",
       "1                         0.0                     0.0               0.0   \n",
       "2                         0.0                     0.0               0.0   \n",
       "3                         0.0                     0.0               0.0   \n",
       "4                         0.0                     0.0               0.0   \n",
       "\n",
       "   PTRACCAT_White  PTMARRY_Married  PTMARRY_Never married  PTMARRY_Unknown  \\\n",
       "0             1.0              1.0                    0.0              0.0   \n",
       "1             1.0              1.0                    0.0              0.0   \n",
       "2             1.0              1.0                    0.0              0.0   \n",
       "3             1.0              1.0                    0.0              0.0   \n",
       "4             1.0              1.0                    0.0              0.0   \n",
       "\n",
       "   PTMARRY_Widowed  FLDSTRENG_3 Tesla MRI  \\\n",
       "0              0.0                    0.0   \n",
       "1              0.0                    0.0   \n",
       "2              0.0                    0.0   \n",
       "3              0.0                    0.0   \n",
       "4              0.0                    0.0   \n",
       "\n",
       "   FSVERSION_Cross-Sectional FreeSurfer (FreeSurfer Version 4.3)  \n",
       "0                                                1.0              \n",
       "1                                                1.0              \n",
       "2                                                1.0              \n",
       "3                                                1.0              \n",
       "4                                                1.0              \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to run a few different types of regressions on this 'full' data set using each cognitive test as a response variable. We'll create a matrix of R^2 values, and use that to decide which model should be used as our 'meta test'. **ALSO**: should we be standardizing the continuous variables??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_score(df, response_col_name, model):\n",
    "    # returns TEST score based on model fitted to data with specified response var\n",
    "    # response_col_name is a string\n",
    "    # model is an unfitted sklearn model\n",
    "    # would be nice to add a polynomial features option\n",
    "    np.random.seed(9001)\n",
    "    msk = np.random.rand(len(df)) < .75\n",
    "    \n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "        \n",
    "    predictors = [i for i in df.columns if i not in response_col_name]\n",
    "    x = train[predictors]\n",
    "    y = train[response_col_name]\n",
    "    \n",
    "    Xt = test[predictors]\n",
    "    yt = test[response_col_name]        \n",
    "    \n",
    "    model.fit(x,y)\n",
    "    test_score = model.score(Xt, yt)\n",
    "    return test_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_df(df,response_vars,model_dict):\n",
    "    # returns a dataframes of TEST r^2 values\n",
    "    # response_vars is a list of strings\n",
    "    # model_dict is a dictionary of unfitted sklearn models\n",
    "    \n",
    "    keys = list(model_dict.keys())\n",
    "    scores = np.zeros((len(response_vars),len(keys)))\n",
    "    \n",
    "    for col, model in enumerate(keys):\n",
    "        for row, response in enumerate(response_vars):\n",
    "            scores[row,col] = split_and_score(df,response,model_dict[model])\n",
    "   \n",
    "    score_df = pd.DataFrame(scores,columns=[keys],index=response_vars)\n",
    "\n",
    "    return score_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_tests = ['MMSE','RAVLT_perc_forgetting','FAQ']\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 5)\n",
    "lin_reg = LinearRegression(fit_intercept = True)\n",
    "ridge = RidgeCV()\n",
    "lasso = LassoCV()\n",
    "\n",
    "models = {}\n",
    "models['KNN'] = knn\n",
    "models['LinearRegression'] = lin_reg\n",
    "models['Ridge'] = ridge\n",
    "models['Lasso'] = lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMSE</th>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.684882</td>\n",
       "      <td>0.685186</td>\n",
       "      <td>0.190325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.325548</td>\n",
       "      <td>0.325082</td>\n",
       "      <td>0.036030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAQ</th>\n",
       "      <td>0.283943</td>\n",
       "      <td>0.782938</td>\n",
       "      <td>0.779865</td>\n",
       "      <td>0.187039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            KNN  LinearRegression     Ridge     Lasso\n",
       "MMSE                   0.261538          0.684882  0.685186  0.190325\n",
       "RAVLT_perc_forgetting  0.009418          0.325548  0.325082  0.036030\n",
       "FAQ                    0.283943          0.782938  0.779865  0.187039"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_score_df(full_data,cog_tests,models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
